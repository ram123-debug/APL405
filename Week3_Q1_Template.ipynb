{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN9IenP7l3TB0951P0di5JA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ram123-debug/APL405/blob/main/Week3_Q1_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtV6A_uXxnfK"
      },
      "outputs": [],
      "source": [
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Week3_Template_LR.ipynb\n",
        "Automatically generated by Colaboratory.\n",
        "# Logistic  Regression\n",
        "Fill the blank spaces as required. \n",
        "Do not change name of any class, method name.\n",
        "\"\"\"\n",
        "\n",
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "import numpy as np\n",
        "from scipy import optimize\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot\n",
        "\n",
        "class lr:\n",
        "    # Data cleaning and finding the mean of the column titled \"MaxTemp\"\n",
        "    def data_clean(self,data):\n",
        "        # 'data' is a dataframe imported from '.csv' file using 'pandas'\n",
        "        # Perform data cleaning steps sequentially as mentioned in assignment\n",
        "        \n",
        "        X=data.drop(['Date','Location','Evaporation','Sunshine','WindGustDir','WindDir9am','WindDir3pm','RainTomorrow'],axis=1)\n",
        "        data['RainTomorrow'] = [ 1 if x == 'Yes' else 0 for x in data['RainTomorrow']]\n",
        "        Y=data['RainTomorrow']\n",
        "        data=X\n",
        "        min_temp_mean=data['MinTemp'].mean(skipna=True)\n",
        "        max_temp_mean=data['MaxTemp'].mean(skipna=True)\n",
        "        Rainfall_mean=data['Rainfall'].mean(skipna=True)\n",
        "        WindGustSpeed_mean=data['WindGustSpeed'].mean(skipna=True)\n",
        "        WindSpeed9am_mean=data['WindSpeed9am'].mean(skipna=True)\n",
        "        WindSpeed3pm_mean=data['WindSpeed3pm'].mean(skipna=True)\n",
        "        Humidity9am_mean=data['Humidity9am'].mean(skipna=True)\n",
        "        Humidity3pm_mean=data['Humidity3pm'].mean(skipna=True)\n",
        "        Pressure9am_mean=data['Pressure9am'].mean(skipna=True)\n",
        "        Pressure3pm_mean=data['Pressure3pm'].mean(skipna=True)\n",
        "        Cloud9am_mean=data['Cloud9am'].mean(skipna=True)\n",
        "        Cloud3pm_mean=data['Cloud3pm'].mean(skipna=True)\n",
        "        Temp9am_mean=data['Temp9am'].mean(skipna=True)\n",
        "        Temp3pm_mean=data['Temp3pm'].mean(skipna=True)\n",
        "        data['MinTemp']=data['MinTemp'].fillna(min_temp_mean)\n",
        "        data['MaxTemp']=data['MaxTemp'].fillna(max_temp_mean)\n",
        "        data['Rainfall']=data['Rainfall'].fillna(Rainfall_mean)\n",
        "        data['WindGustSpeed']=data['WindGustSpeed'].fillna(WindGustSpeed_mean)\n",
        "        data['WindSpeed9am']=data['WindSpeed9am'].fillna(WindSpeed9am_mean)\n",
        "        data['WindSpeed3pm']=data['WindSpeed3pm'].fillna(WindSpeed3pm_mean)\n",
        "        data['Humidity9am']=data['Humidity9am'].fillna(Humidity9am_mean)\n",
        "        data['Humidity3pm']=data['Humidity3pm'].fillna(Humidity3pm_mean)\n",
        "        data['Pressure9am']=data['Pressure9am'].fillna(Pressure9am_mean)\n",
        "        data['Pressure3pm']=data['Pressure3pm'].fillna(Pressure3pm_mean)\n",
        "        data['Cloud9am']=data['Cloud9am'].fillna(Cloud9am_mean)\n",
        "        data['Cloud3pm']=data['Cloud3pm'].fillna(Cloud3pm_mean)\n",
        "        data['Temp9am']=data['Temp9am'].fillna(Temp9am_mean)\n",
        "        data['Temp3pm']=data['Temp3pm'].fillna(Temp3pm_mean)\n",
        "        def normalize(df):\n",
        "           result = df.copy()\n",
        "           for feature_name in df.columns:\n",
        "              max_value = df[feature_name].max()\n",
        "              min_value = df[feature_name].min()\n",
        "              result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
        "           return result\n",
        "         Norm_Data=normalize(data)\n",
        "         MaxTemp_Mean=Norm_Data['MaxTemp'].mean()\n",
        "\n",
        "        \n",
        "        X =np.array(Norm_Data)         # X (Feature matrix) - should be numpy array\n",
        "        y =Y          # y (prediction vector) - should be numpy arrays\n",
        "        mean =MaxTemp_Mean       # Mean of a the normalized \"MaxTemp\" column rounded off to 3 decimal places\n",
        "    \n",
        "        return X, y, mean\n",
        "\n",
        "class costing:\n",
        "    # define the function needed to evaluate cost function\n",
        "    # Input 'z' could be a scalar or a 1D vector\n",
        "    def sigmoid(self,z):\n",
        "        \n",
        "        \n",
        "        \n",
        "        return g\n",
        "    \n",
        "    # Regularized cost function definition\n",
        "    def costFunctionReg(self,w,X,y,lambda_):\n",
        "        \n",
        "        \n",
        "        \n",
        "        J =             # Cost 'J' should be a scalar\n",
        "        grad =          # Gradient 'grad' should be a vector\n",
        "        \n",
        "        return J, grad\n",
        "    \n",
        "    # Prediction based on trained model\n",
        "    # Use sigmoid function to calculate probability rounded off to either 0 or 1\n",
        "    def predict(self,w,X):\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        p =             # 'p' should be a vector of size equal to that of vector 'y'\n",
        "        \n",
        "        return p\n",
        "    \n",
        "    # Optimization defintion\n",
        "    def minCostFun(self, w_ini, X_train, y_train, iters):\n",
        "        # iters - Maximum no. of iterations; X_train - Numpy array\n",
        "        lambda_ =       # Regularization parameter\n",
        "        X_train =       # Add '1' for bias term\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        w_opt =         # Optimized weights rounded off to 3 decimal places\n",
        "        \n",
        "        acrcy =         # Training set accuracy (in %) rounded off to 3 decimal places\n",
        "        \n",
        "        return w_opt, acrcy\n",
        "    \n",
        "    # Calculate testing accuracy\n",
        "    def TestingAccu(self, w_opt, X_test, y_test):\n",
        "        w_opt =         # Optimum weights calculated using training data\n",
        "        X_test =        # Add '1' for bias term\n",
        "        \n",
        "        \n",
        "        \n",
        "        acrcy_test =    # Testing set accuracy (in %) rounded off to 3 decimal places\n",
        "        \n",
        "        return acrcy_test"
      ]
    }
  ]
}